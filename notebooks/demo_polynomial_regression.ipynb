{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression Demo\n",
    "This notebook shows how polynomial regression can model nonlinear relationships by expanding features with powers of the original input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.datasets import make_regression\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate nonlinear data\n",
    "We start from `make_regression` and add a quadratic term to create curvature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=200, n_features=1, noise=8.0, random_state=42, bias=30.0)\n",
    "y = y + 0.8 * np.square(X[:, 0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, alpha=0.6)\n",
    "plt.title('Synthetic nonlinear data')\n",
    "plt.xlabel('Feature X')\n",
    "plt.ylabel('Target y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a polynomial regression pipeline\n",
    "Increasing the polynomial degree adds flexibility. Try changing the `degree` variable to see underfitting vs. overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 3\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "We report MAE, MSE, RMSE, and RÂ²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "metrics = {\n",
    "    'MAE': mean_absolute_error(y_test, y_pred),\n",
    "    'MSE': mse,\n",
    "    'RMSE': np.sqrt(mse),\n",
    "    'R2': r2_score(y_test, y_pred)\n",
    "}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the fitted curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(X.min() - 5, X.max() + 5, 300).reshape(-1, 1)\n",
    "y_plot = model.predict(X_plot)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(X_train, y_train, alpha=0.5, label='train')\n",
    "plt.scatter(X_test, y_test, alpha=0.8, label='test')\n",
    "plt.plot(X_plot, y_plot, color='darkorange', linewidth=2.5, label='prediction')\n",
    "plt.xlabel('Feature X')\n",
    "plt.ylabel('Target y')\n",
    "plt.title(f'Polynomial Regression (degree={degree})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Higher degree = more flexible curve but risk of overfitting.\n",
    "- Regularization (Ridge/Lasso) can help tame large coefficients.\n",
    "- For multi-dimensional features, consider scaling before polynomial expansion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
